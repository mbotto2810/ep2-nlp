{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CsCJSgEc_ZKP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpYMIv8R_ZKV"
      },
      "source": [
        "# pre processamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMCSFSxRBETz",
        "outputId": "b3ed43e7-2bd3-4232-80ce-c4ff35d0a41b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/B2W-Reviews01.csv'"
      ],
      "metadata": {
        "id": "TFqx2TvuBMwL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sJOuYt0_ZKY",
        "outputId": "a455552a-bc42-4605-b206-62f4594f9b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-cc35be6aee29>:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path)\n"
          ]
        }
      ],
      "source": [
        "#df = pd.read_csv('../data/B2W-Reviews01.csv')\n",
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iOJRNYhu_ZKa"
      },
      "outputs": [],
      "source": [
        "cols = ['review_text']\n",
        "df = df[cols]\n",
        "df.rename(columns={'review_text': 'texto'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x3Hkh3U7_ZKa"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuB27R4J_ZKa"
      },
      "source": [
        "# tarefa 1 - regressao na quantidade de vogais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I0U-Bp1N_ZKa"
      },
      "outputs": [],
      "source": [
        "def calcular_densidade_vogais(texto):\n",
        "    texto = re.sub(r'[^A-Za-zÇçÃãÁáÉéÍíÓóÚúÀàÊêÔô]', '', texto)  # Remover caracteres não-alfabéticos\n",
        "    total_letras = len(texto)\n",
        "    total_vogais = len(re.findall(r'[AEIOUaeiouÁÉÍÓÚáéíóúÀàÃãÊêÔô]', texto))\n",
        "    return total_vogais / total_letras if total_letras > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GuBA8-Ls_ZKa"
      },
      "outputs": [],
      "source": [
        "df['densidades'] = df['texto'].apply(calcular_densidade_vogais)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaHDw2rZ_ZKb",
        "outputId": "3592f405-82b1-4374-f87c-92cf3c8f0ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ],
      "source": [
        "# 10 000  sentencas para aumentar a velocidade de treinamento\n",
        "# TODO: Taking the first samples may induce bias\n",
        "df = df[:10000]\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk6Lsiym_ZKb",
        "outputId": "7e4d1267-297f-4e3a-b9af-f260fba1fb48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000 train examples\n",
            "2000 validation examples\n",
            "2000 test examples\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separar o conjunto de dados em treino, teste e validacao\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_df, val_df  = train_test_split(train_df, test_size=0.25, random_state=42)\n",
        "\n",
        "print(len(train_df), 'train examples')\n",
        "print(len(val_df), 'validation examples')\n",
        "print(len(test_df), 'test examples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YAsCeT6_ZKb",
        "outputId": "3a2741c7-c0b0-437f-dec0-62cdc4967a2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#train_df.head(2)\n",
        "len(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlMsH8fw_ZKb"
      },
      "source": [
        "## BERTimbau fine tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3pXPveB_ZKb",
        "outputId": "9cf4979a-bfa4-482d-b9ca-9bf5bc073512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GF5AG0AL_ZKc"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, optim\n",
        "\n",
        "# Tokenizer e Modelo do BERTimbau\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Classe do Dataset\n",
        "class TextoDataset(Dataset):\n",
        "    def __init__(self, textos, densidades):\n",
        "        self.textos = textos\n",
        "        self.densidades = densidades\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.textos)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        texto = self.textos[idx]\n",
        "        densidade = self.densidades[idx]\n",
        "        inputs = tokenizer(texto, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "        return inputs, torch.tensor(densidade, dtype=torch.float)\n",
        "\n",
        "# Criar instâncias do TextoDataset\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "train_dataset = TextoDataset(train_df['texto'], train_df['densidades'])\n",
        "validate_dataset = TextoDataset(val_df['texto'], val_df['densidades'])\n",
        "test_dataset = TextoDataset(test_df['texto'], test_df['densidades'])\n",
        "\n",
        "# Criar DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validate_loader = DataLoader(validate_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uKZLJNiV_ZKc"
      },
      "outputs": [],
      "source": [
        "class BertForRegression(nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(BertForRegression, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.regressor = nn.Linear(768, 1)  # 768 é a dimensão do vetor de características do BERT\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        return self.regressor(pooled_output)\n",
        "\n",
        "model = BertForRegression(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o6Tg1Mtr_ZKc"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "\n",
        "# Função de perda e otimizador\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xxaCI98M_ZKc"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, validate_loader, epochs=3):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Train loop with tqdm\n",
        "        train_loop = tqdm(train_loader, leave=True)\n",
        "        for inputs, labels in train_loop:\n",
        "            input_ids = inputs['input_ids'].to(device)\n",
        "            attention_mask = inputs['attention_mask'].to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            input_ids = input_ids.view(-1, input_ids.size(-1))\n",
        "            attention_mask = attention_mask.view(-1, attention_mask.size(-1))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            outputs = outputs.view(-1, 1)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Update tqdm description with current loss\n",
        "            train_loop.set_description(f'Epoch {epoch+1}')\n",
        "            train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        print('\\n Validating...')\n",
        "\n",
        "        # Validation loop with tqdm\n",
        "        validate_loop = tqdm(validate_loader, leave=True)\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in validate_loop:\n",
        "                input_ids = inputs['input_ids'].to(device)\n",
        "                attention_mask = inputs['attention_mask'].to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                input_ids = input_ids.view(-1, input_ids.size(-1))\n",
        "                attention_mask = attention_mask.view(-1, attention_mask.size(-1))\n",
        "\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "                outputs = outputs.view(-1, 1)\n",
        "\n",
        "                # Colocar ideia aqui\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "\n",
        "                validate_loop.set_postfix(val_loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}, Validation Loss: {val_loss/len(validate_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSZR-tFX_ZKc",
        "outputId": "02c74058-d1e5-4085-dace-04bf324ba877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch 1: 100%|██████████| 375/375 [02:56<00:00,  2.13it/s, loss=0.00103]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.03it/s, val_loss=0.00131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 0.00398437637106205, Validation Loss: 0.001700983684277162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 375/375 [02:55<00:00,  2.14it/s, loss=0.00923]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.00it/s, val_loss=0.00121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Training Loss: 0.001985398019508769, Validation Loss: 0.0015744098897557705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 375/375 [02:55<00:00,  2.14it/s, loss=0.000478]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.00it/s, val_loss=0.0017]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Training Loss: 0.0017883167186907181, Validation Loss: 0.001958635548595339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_model(model, criterion, optimizer, train_loader, validate_loader, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the entire model\n",
        "torch.save(model, 'reg_model.pth')"
      ],
      "metadata": {
        "id": "1qVR4fZSG2HE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ERkI_HZK_ZKd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    return mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true += 1e-5 # Numeric problems\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def pearson_correlation(y_true, y_pred):\n",
        "    corr, _ = pearsonr(y_true, y_pred)\n",
        "    return corr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_test(model, test_loader):\n",
        "    y_pred_model = []\n",
        "    y_true       = []\n",
        "\n",
        "    # Evaluating the model of density of vowels per sentence on the test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            input_ids = inputs['input_ids'].to(device)\n",
        "            attention_mask = inputs['attention_mask'].to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            input_ids = input_ids.view(-1, input_ids.size(-1))\n",
        "            attention_mask = attention_mask.view(-1, attention_mask.size(-1))\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            outputs = outputs.view(-1, 1)\n",
        "\n",
        "            y_pred_model.extend(outputs.view(-1).cpu().numpy())\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Convert predictions and true values to numpy arrays\n",
        "    y_pred_model = np.array(y_pred_model)\n",
        "    y_true = np.array(y_true)\n",
        "    return y_true, y_pred_model"
      ],
      "metadata": {
        "id": "lsEdTTxN4JJ3"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "4zOueK47_ZKd"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model of density of vowels per sentence on the test set\n",
        "y_true_sentence, y_pred_model_sentence = eval_test(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model of density of vowels on the global density of the test\n",
        "# Use the train dataset to prevent leakage\n",
        "global_density = list(train_df.texto.values)\n",
        "separator = ' '\n",
        "global_density = calcular_densidade_vogais(separator.join(global_density))\n",
        "\n",
        "test_df2 = test_df.copy()\n",
        "test_df2 = test_df2.reset_index(drop=True)\n",
        "test_df2['densidades'] = global_density\n",
        "\n",
        "test_dataset2 = TextoDataset(test_df2['texto'], test_df2['densidades'])\n",
        "test_loader2 = DataLoader(test_dataset2, batch_size=BATCH_SIZE)\n",
        "\n",
        "y_true_global, y_pred_model_global = eval_test(model, test_loader2)"
      ],
      "metadata": {
        "id": "bXEW-dHe4YSh"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model of density of vowels on the first word density\n",
        "def get_first_word_density(text):\n",
        "    list_word = text.split(' ')\n",
        "    word = list_word[0]\n",
        "    return calcular_densidade_vogais(word)\n",
        "\n",
        "first_density = list(test_df['texto'].apply(lambda x : get_first_word_density(x)).values)\n",
        "\n",
        "test_df3 = test_df.copy()\n",
        "test_df3 = test_df3.reset_index(drop=True)\n",
        "test_df3['densidades'] = first_density\n",
        "\n",
        "test_dataset3 = TextoDataset(test_df3['texto'], test_df3['densidades'])\n",
        "test_loader3 = DataLoader(test_dataset3, batch_size=BATCH_SIZE)\n",
        "\n",
        "y_true_first, y_pred_model_first = eval_test(model, test_loader3)"
      ],
      "metadata": {
        "id": "42JVmWtr4YVR"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model of density of vowels on the last word density\n",
        "def get_last_word_density(text):\n",
        "    list_word = text.split(' ')\n",
        "    word = list_word[len(list_word)-1]\n",
        "    return calcular_densidade_vogais(word)\n",
        "\n",
        "last_density = list(test_df['texto'].apply(lambda x : get_first_word_density(x)).values)\n",
        "\n",
        "test_df4 = test_df.copy()\n",
        "test_df4 = test_df4.reset_index(drop=True)\n",
        "test_df4['densidades'] = last_density\n",
        "\n",
        "test_dataset4 = TextoDataset(test_df4['texto'], test_df4['densidades'])\n",
        "test_loader4 = DataLoader(test_dataset4, batch_size=BATCH_SIZE)\n",
        "\n",
        "y_true_last, y_pred_model_last = eval_test(model, test_loader4)\n"
      ],
      "metadata": {
        "id": "jAUna0gQ4nZT"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(y_true, y_pred_model):\n",
        "    return {\n",
        "        \"RMSE\": rmse(y_true, y_pred_model),\n",
        "        \"MAE\": mae(y_true, y_pred_model),\n",
        "        \"MAPE\": mape(y_true, y_pred_model),\n",
        "        \"R2\": r2_score(y_true, y_pred_model),\n",
        "        \"Pearson\": pearson_correlation(y_true, y_pred_model)\n",
        "    }"
      ],
      "metadata": {
        "id": "Ka-L3nqS2uDS"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_dict_first = get_metrics(y_true_first, y_pred_model_first)\n",
        "metrics_dict_last = get_metrics(y_true_last, y_pred_model_last)\n",
        "metrics_dict_sentence = get_metrics(y_true_sentence, y_pred_model_sentence)\n",
        "metrics_dict_global = get_metrics(y_true_global, y_pred_model_global)\n",
        "\n",
        "metrics_df = pd.DataFrame([metrics_dict_first,\n",
        "                           metrics_dict_last,\n",
        "                           metrics_dict_global,\n",
        "                           metrics_dict_sentence], index=\n",
        "                            ['Using only the first word',\n",
        "                             'Using only the last word',\n",
        "                             'Using the global density',\n",
        "                             'Using the density per sentence'])\n",
        "metrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "tolFkmlw-fFZ",
        "outputId": "db13392a-469a-4ee0-c2ec-e40529a5a6bb"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(stats.ConstantInputWarning(msg))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    RMSE       MAE          MAPE  \\\n",
              "Using only the first word       0.242824  0.163226  46250.650024   \n",
              "Using only the last word        0.242824  0.163226  46250.650024   \n",
              "Using the global density        0.018572  0.018131      3.759262   \n",
              "Using the density per sentence  0.046373  0.029782   6907.958221   \n",
              "\n",
              "                                          R2   Pearson  \n",
              "Using only the first word      -2.881663e-01  0.024313  \n",
              "Using only the last word       -2.881663e-01  0.024313  \n",
              "Using the global density       -2.429719e+10       NaN  \n",
              "Using the density per sentence -1.634248e-01  0.134490  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58191c4b-b340-44a4-b670-c3ce4025f5af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>R2</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Using only the first word</th>\n",
              "      <td>0.242824</td>\n",
              "      <td>0.163226</td>\n",
              "      <td>46250.650024</td>\n",
              "      <td>-2.881663e-01</td>\n",
              "      <td>0.024313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Using only the last word</th>\n",
              "      <td>0.242824</td>\n",
              "      <td>0.163226</td>\n",
              "      <td>46250.650024</td>\n",
              "      <td>-2.881663e-01</td>\n",
              "      <td>0.024313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Using the global density</th>\n",
              "      <td>0.018572</td>\n",
              "      <td>0.018131</td>\n",
              "      <td>3.759262</td>\n",
              "      <td>-2.429719e+10</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Using the density per sentence</th>\n",
              "      <td>0.046373</td>\n",
              "      <td>0.029782</td>\n",
              "      <td>6907.958221</td>\n",
              "      <td>-1.634248e-01</td>\n",
              "      <td>0.134490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58191c4b-b340-44a4-b670-c3ce4025f5af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58191c4b-b340-44a4-b670-c3ce4025f5af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58191c4b-b340-44a4-b670-c3ce4025f5af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ce6b9a3-95e9-437a-996f-df51ef5c0621\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ce6b9a3-95e9-437a-996f-df51ef5c0621')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ce6b9a3-95e9-437a-996f-df51ef5c0621 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification problem"
      ],
      "metadata": {
        "id": "sxd-6vHzCFu2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ljCKsfKy_ZKd"
      },
      "outputs": [],
      "source": [
        "def classify_vowel_density(density):\n",
        "    if density < 1/3:\n",
        "        return 0  # Class 1\n",
        "    elif 1/3 <= density <= 2/3:\n",
        "        return 1  # Class 2\n",
        "    else:\n",
        "        return 2  # Class 3\n",
        "\n",
        "# Applying the classification function to the 'densidades' column\n",
        "df['labels'] = df['densidades'].apply(classify_vowel_density)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xlGQJP7_ZKd",
        "outputId": "06501755-a21d-43c1-f372-0d3d307ee776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000 train examples\n",
            "2000 validation examples\n",
            "2000 test examples\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_df, val_df  = train_test_split(train_df, test_size=0.25, random_state=42)\n",
        "\n",
        "print(len(train_df), 'train examples')\n",
        "print(len(val_df), 'validation examples')\n",
        "print(len(test_df), 'test examples')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classe do Dataset\n",
        "class TextoDataset(Dataset):\n",
        "    def __init__(self, textos, labels):\n",
        "        self.textos = textos\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.textos)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        texto = self.textos[idx]\n",
        "        label = self.labels[idx]\n",
        "        inputs = tokenizer(texto, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "        input_ids = inputs['input_ids'].squeeze(0)  # Remove batch dimension\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)  # Remove batch dimension\n",
        "        return input_ids, attention_mask, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Preparando DataFrames (assumindo que você já os tem divididos em treino, validação e teste)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "# Substitua 'densidades' por uma coluna apropriada de etiquetas de classe\n",
        "train_dataset = TextoDataset(train_df['texto'], train_df['labels'])\n",
        "validate_dataset = TextoDataset(val_df['texto'], val_df['labels'])\n",
        "test_dataset = TextoDataset(test_df['texto'], test_df['labels'])\n",
        "\n",
        "# Criar DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validate_loader = DataLoader(validate_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "ofZAcJolCM4R"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining and training the model"
      ],
      "metadata": {
        "id": "j-hVPDq1DUcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unbalanced case"
      ],
      "metadata": {
        "id": "SpaJSEfhEhKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForClassification(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes):\n",
        "        super(BertForClassification, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        # Assuming 768-dimensional feature vectors from BERT, with num_classes outputs\n",
        "        self.classifier = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        return self.classifier(pooled_output)\n",
        "\n",
        "# Example usage\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')  # Use a pre-trained BERT model\n",
        "model = BertForClassification(bert_model, num_classes=3)  # Specify the number of classes\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Loss function and optimizer for classification (using CrossEntropyLoss for multi-class)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "chk146AnDV7Z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, validate_loader, num_classes, epochs=3):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Train loop with tqdm\n",
        "        train_loop = tqdm(train_loader, leave=True)\n",
        "        for input_ids, attention_mask, labels in train_loop:\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "\n",
        "            # For classification, outputs are likely to be logits, need to reshape for CrossEntropyLoss\n",
        "            outputs = outputs.view(-1, num_classes)  # num_classes is the number of classes in your classification task\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Update tqdm description with current loss\n",
        "        train_loop.set_description(f'Epoch {epoch+1}')\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        print('\\n Validating...')\n",
        "\n",
        "        # Validation loop with tqdm\n",
        "        validate_loop = tqdm(validate_loader, leave=True)\n",
        "        with torch.no_grad():\n",
        "            for input_ids, attention_mask, labels in validate_loop:\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "                outputs = outputs.view(-1, num_classes)  # Adjusted to match the number of classes\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                validate_loop.set_postfix(val_loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}, Validation Loss: {val_loss/len(validate_loader)}\")"
      ],
      "metadata": {
        "id": "CWFv4BMdDXTu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, criterion, optimizer, train_loader, validate_loader, epochs=3, num_classes=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2iBC16sEQDk",
        "outputId": "e4420e51-181d-4a1b-dc8c-cecf5959c90d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:53<00:00,  2.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.01it/s, val_loss=0.000997]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.010754324772395194, Validation Loss: 0.01702773686358705\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:54<00:00,  2.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.03it/s, val_loss=0.0143]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Training Loss: 0.0077529994996730234, Validation Loss: 0.021387031000107526\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:54<00:00,  2.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.01it/s, val_loss=0.00117]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Training Loss: 0.005964060601700718, Validation Loss: 0.014728623283910565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:53<00:00,  2.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.03it/s, val_loss=0.000512]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.003872952530509792, Validation Loss: 0.01952215628011618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:53<00:00,  2.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.04it/s, val_loss=0.00055]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Training Loss: 0.0028478361713932827, Validation Loss: 0.018527215126494412\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:53<00:00,  2.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.04it/s, val_loss=0.000111]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Training Loss: 0.002267196642506557, Validation Loss: 0.020303341994353106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:53<00:00,  2.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.04it/s, val_loss=7.81e-5]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.002039365710147346, Validation Loss: 0.01999900148474262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 375/375 [02:53<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.09it/s, val_loss=4.98e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Training Loss: 0.0016443868269755816, Validation Loss: 0.022644582486653235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 375/375 [02:53<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:20<00:00,  6.09it/s, val_loss=6.19e-5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Training Loss: 0.0018175426693827223, Validation Loss: 0.025689835368015338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the entire model\n",
        "torch.save(model, 'classification_model.pth')"
      ],
      "metadata": {
        "id": "P0zCjlmGF27S"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, labels in test_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "# Get predictions and true labels\n",
        "preds, labels = evaluate_model(model, test_loader, device)\n",
        "\n",
        "# Total accuracy\n",
        "total_accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(labels, preds)\n",
        "per_class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "sensitivity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
        "specificity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
        "\n",
        "# Output the metrics\n",
        "print(\"Total Accuracy:\", total_accuracy)\n",
        "print(\"Per Class Accuracy:\", per_class_accuracy)\n",
        "print(\"Sensitivity (Recall) per Class:\", sensitivity)\n",
        "print(\"Specificity per Class:\", specificity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4o1u283KjLz",
        "outputId": "f10bd765-dc2e-4079-f19f-64acfa23eb57"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuracy: 0.998\n",
            "Per Class Accuracy: [0.81818182 0.99899346 1.        ]\n",
            "Sensitivity (Recall) per Class: [0.81818182 0.99899346 1.        ]\n",
            "Specificity per Class: [0.81818182 0.99899346 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balanced case"
      ],
      "metadata": {
        "id": "v7KHRw3jEjXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"W\""
      ],
      "metadata": {
        "id": "Uy9ExBKhEkTR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}